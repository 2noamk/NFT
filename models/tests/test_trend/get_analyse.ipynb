{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "def find_best_row(group):\n",
    "    min_all = group.loc[(group['test_mse'] == group['test_mse'].min()) & \n",
    "                        (group['test_smape'] == group['test_smape'].min()) & \n",
    "                        (group['test_mase'] == group['test_mase'].min())]\n",
    "\n",
    "    if not min_all.empty:\n",
    "        return min_all.iloc[0]\n",
    "    \n",
    "    for metric_combination in [('test_mse', 'test_smape'), ('test_mse', 'test_mase'), ('test_smape', 'test_mase')]:\n",
    "        min_two = group.loc[(group[metric_combination[0]] == group[metric_combination[0]].min()) & \n",
    "                            (group[metric_combination[1]] == group[metric_combination[1]].min())]\n",
    "        if not min_two.empty:\n",
    "            return min_two.iloc[0]\n",
    "        \n",
    "    return group.loc[group['test_mase'] == group['test_mase'].min()].iloc[0]\n",
    "\n",
    "base_path = f\"/home/../multiTS/NFT/models/tests/test_trend/\"\n",
    "df = pd.read_excel(f'{base_path}evaluate_sinusodial_trend_on_syntatic_data.xlsx')\n",
    "\n",
    "poly_true = df[df['Is Poly'] == True]\n",
    "poly_false = df[df['Is Poly'] == False]\n",
    "\n",
    "best_rows_poly_true = poly_true.groupby(['Lookback', 'Horizon', 'Vars']).apply(find_best_row).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1266, 11)\n",
      "(632, 11)\n",
      "(634, 11)\n",
      "(53, 11)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(poly_true.shape)\n",
    "print(poly_false.shape)\n",
    "print(best_rows_poly_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "def find_best_row(group):\n",
    "    min_all = group.loc[(group['test_mse'] == group['test_mse'].min()) & \n",
    "                        (group['test_smape'] == group['test_smape'].min()) & \n",
    "                        (group['test_mase'] == group['test_mase'].min())]\n",
    "\n",
    "    if not min_all.empty:\n",
    "        return min_all.iloc[0]\n",
    "    \n",
    "    for metric_combination in [('test_mse', 'test_smape'), ('test_mse', 'test_mase'), ('test_smape', 'test_mase')]:\n",
    "        min_two = group.loc[(group[metric_combination[0]] == group[metric_combination[0]].min()) & \n",
    "                            (group[metric_combination[1]] == group[metric_combination[1]].min())]\n",
    "        if not min_two.empty:\n",
    "            return min_two.iloc[0]\n",
    "        \n",
    "    return group.loc[group['test_mase'] == group['test_mase'].min()].iloc[0]\n",
    "\n",
    "base_path = f\"/home/../multiTS/NFT/models/tests/test_trend/\"\n",
    "df = pd.read_excel(f'{base_path}evaluate_sinusodial_trend_on_syntatic_data.xlsx')\n",
    "\n",
    "poly_true = df[df['Is Poly'] == True]\n",
    "poly_false = df[df['Is Poly'] == False]\n",
    "\n",
    "best_rows_poly_true = poly_true.groupby(['Lookback', 'Horizon', 'Vars']).apply(find_best_row).reset_index(drop=True)\n",
    "best_rows_combined = pd.DataFrame()\n",
    "\n",
    "for _, row in best_rows_poly_true.iterrows():\n",
    "    matching_row = poly_false[\n",
    "        (poly_false['Lookback'] == row['Lookback']) & \n",
    "        (poly_false['Horizon'] == row['Horizon']) & \n",
    "        (poly_false['Vars'] == row['Vars']) & \n",
    "        (poly_false['Epochs'] == row['Epochs']) & \n",
    "        (poly_false['Stacks'] == row['Stacks']) & \n",
    "        (poly_false['Dagree'] == row['Dagree']) & \n",
    "        (poly_false['Blocks'] == row['Blocks'])\n",
    "    ]\n",
    "    best_rows_combined = pd.concat([best_rows_combined, pd.DataFrame([row])], ignore_index=True)\n",
    "    if not matching_row.empty:\n",
    "        best_rows_combined = pd.concat([best_rows_combined, matching_row.head(1)], ignore_index=True)\n",
    "\n",
    "if best_rows_combined.empty:\n",
    "    print(\"No matching rows were found.\")\n",
    "else:\n",
    "    best_rows_combined.to_excel(f'{base_path}best_rows_combined.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the combined Excel file\n",
    "best_combined = pd.read_excel('/home/../multiTS/NFT/results/combined_data.xlsx')\n",
    "\n",
    "# Initialize the new column with NaN (Not a Number)\n",
    "best_combined['Poly_Performance'] = pd.NA\n",
    "\n",
    "# Define the metrics you want to compare. You can add more metrics here based on your actual data.\n",
    "metrics = ['test_mse', 'test_smape', 'test_mase']\n",
    "\n",
    "# Sort the dataframe for correct row comparisons\n",
    "best_combined.sort_values(by=['Lookback', 'Horizon'], inplace=True)\n",
    "\n",
    "# Go over each two rows and compare their metrics\n",
    "for i in range(0, len(best_combined) - 1, 2):  # Step by 2 since we're comparing pairs\n",
    "    row_1 = best_combined.iloc[i]\n",
    "    row_2 = best_combined.iloc[i + 1]\n",
    "\n",
    "    # Assuming row_1 is Poly=True and row_2 is Poly=False because of sorting, if not, check and swap\n",
    "    if not row_1['Is Poly']:\n",
    "        row_1, row_2 = row_2, row_1  # Swap if the first row is not Poly=True\n",
    "    \n",
    "    # Compare the metrics\n",
    "    if all(row_1[metric] <= row_2[metric] for metric in metrics):\n",
    "        # If all metrics of row_1 (Poly=True) are better or equal\n",
    "        best_combined.at[i, 'Poly_Performance'] = 1\n",
    "        best_combined.at[i + 1, 'Poly_Performance'] = 0\n",
    "    elif all(row_2[metric] <= row_1[metric] for metric in metrics):\n",
    "        # If all metrics of row_2 (Poly=False) are better or equal\n",
    "        best_combined.at[i, 'Poly_Performance'] = 0\n",
    "        best_combined.at[i + 1, 'Poly_Performance'] = -1\n",
    "\n",
    "# Save the updated DataFrame back to Excel\n",
    "best_combined.to_excel('/home/../multiTS/NFT/models/tests/test_trend/best_rows_combined_updated.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the combined Excel file\n",
    "best_combined = pd.read_excel('/home/../multiTS/NFT/results/combined_data.xlsx')\n",
    "\n",
    "# Initialize the new column with NaN (Not a Number)\n",
    "best_combined['Poly_Performance'] = pd.NA\n",
    "\n",
    "# Define the metrics you want to compare.\n",
    "metrics = ['test_mse', 'test_smape', 'test_mase']\n",
    "\n",
    "# Sort the dataframe for correct row comparisons\n",
    "best_combined.sort_values(by=['Lookback', 'Horizon'], inplace=True)\n",
    "\n",
    "# Initialize an empty list to keep track of rows to remove\n",
    "rows_to_remove = []\n",
    "\n",
    "# Go over each two rows and compare their metrics\n",
    "for i in range(0, len(best_combined) - 1, 2):  # Step by 2 since we're comparing pairs\n",
    "    row_1 = best_combined.iloc[i]\n",
    "    row_2 = best_combined.iloc[i + 1]\n",
    "\n",
    "    # Assuming row_1 is Poly=True and row_2 is Poly=False because of sorting, if not, check and swap\n",
    "    if not row_1['Is Poly']:\n",
    "        row_1, row_2 = row_2, row_1  # Swap if the first row is not Poly=True\n",
    "    \n",
    "    # Compare the metrics\n",
    "    better_metrics = sum(row_1[metric] <= row_2[metric] for metric in metrics)\n",
    "    if better_metrics >= 2:  # If at least two metrics are better or equal for Poly=True\n",
    "        best_combined.at[i, 'Poly_Performance'] = 1\n",
    "        best_combined.at[i + 1, 'Poly_Performance'] = 0\n",
    "    else:\n",
    "        best_combined.at[i, 'Poly_Performance'] = 0\n",
    "        best_combined.at[i + 1, 'Poly_Performance'] = -1\n",
    "        # Mark these rows for removal\n",
    "        rows_to_remove.extend([i, i + 1])\n",
    "\n",
    "# # Remove the rows where Poly=True does not perform better in at least two metrics\n",
    "best_combined.drop(index=rows_to_remove, inplace=True)\n",
    "\n",
    "# Save the updated DataFrame back to Excel\n",
    "best_combined.to_excel('/home/../multiTS/NFT/models/tests/test_trend/removed_updated.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import pandas as pd\n",
    "\n",
    "    # Load the combined Excel file\n",
    "    best_combined = pd.read_excel('/home/../multiTS/NFT/results/combined_data.xlsx')\n",
    "\n",
    "    # Initialize the new columns with extracted substrings\n",
    "    best_combined['series'] = best_combined['Data'].apply(lambda x: x[5:16])\n",
    "    best_combined['year'] = best_combined['Data'].apply(lambda x: x[17:21])\n",
    "\n",
    "    # Initialize the 'Poly_Performance' column with NaN (Not a Number)\n",
    "    best_combined['Poly_Performance'] = pd.NA\n",
    "\n",
    "    # Define the metrics you want to compare.\n",
    "    metrics = ['test_mse', 'test_smape', 'test_mase']\n",
    "\n",
    "    # Sort the dataframe for correct row comparisons\n",
    "    best_combined.sort_values(by=['Lookback', 'Horizon'], inplace=True)\n",
    "\n",
    "    # Initialize an empty list to keep track of rows to remove\n",
    "    rows_to_remove = []\n",
    "\n",
    "    # Go over each two rows and compare their metrics\n",
    "    for i in range(0, len(best_combined) - 1, 2):  # Step by 2 since we're comparing pairs\n",
    "        row_1 = best_combined.iloc[i]\n",
    "        row_2 = best_combined.iloc[i + 1]\n",
    "\n",
    "        # Assuming row_1 is Poly=True and row_2 is Poly=False because of sorting, if not, check and swap\n",
    "        if not row_1['Is Poly']:\n",
    "            row_1, row_2 = row_2, row_1  # Swap if the first row is not Poly=True\n",
    "        \n",
    "        # Compare the metrics\n",
    "        better_metrics = sum(row_1[metric] <= row_2[metric] for metric in metrics)\n",
    "        if better_metrics >= 2:  # If at least two metrics are better or equal for Poly=True\n",
    "            best_combined.at[i, 'Poly_Performance'] = 1\n",
    "            best_combined.at[i + 1, 'Poly_Performance'] = 0\n",
    "        else:\n",
    "            # Mark these rows for removal\n",
    "            rows_to_remove.extend([i, i + 1])\n",
    "\n",
    "    # Remove the rows where Poly=True does not perform better in at least two metrics\n",
    "    best_combined.drop(index=rows_to_remove, inplace=True)\n",
    "\n",
    "    # Save the updated DataFrame back to Excel\n",
    "    best_combined.to_excel('/home/../multiTS/NFT/models/tests/test_trend/best_rows_combined_updated.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the combined Excel file\n",
    "best_combined = pd.read_excel('/home/../multiTS/NFT/results/combined_data.xlsx')\n",
    "\n",
    "# Initialize the new columns with extracted substrings\n",
    "best_combined['series'] = best_combined['Data'].apply(lambda x: x[5:16])\n",
    "best_combined['year'] = best_combined['Data'].apply(lambda x: x[17:21])\n",
    "\n",
    "# Initialize the 'Poly_Performance' column with NaN (Not a Number)\n",
    "best_combined['Poly_Performance'] = pd.NA\n",
    "\n",
    "# Define the metrics you want to compare.\n",
    "metrics = ['test_mse', 'test_smape', 'test_mase']\n",
    "\n",
    "# Sort the dataframe for correct row comparisons\n",
    "best_combined.sort_values(by=['Lookback', 'Horizon', 'Epochs', 'Blocks', 'Data'], inplace=True)\n",
    "\n",
    "# Initialize an empty list to keep track of rows to remove\n",
    "rows_to_remove = []\n",
    "\n",
    "# Go over each two rows and compare their metrics\n",
    "for i in range(0, len(best_combined) - 1, 2):  # Step by 2 since we're comparing pairs\n",
    "    row_1 = best_combined.iloc[i]\n",
    "    row_2 = best_combined.iloc[i + 1]\n",
    "\n",
    "    # Check if the rows have the same values for specified columns and opposite values in 'Is Poly' column\n",
    "    if all(row_1[col] == row_2[col] for col in ['Data', 'Lookback', 'Horizon', 'Epochs', 'Blocks']) and row_1['Is Poly'] != row_2['Is Poly']:\n",
    "        # Assuming row_1 is Poly=True and row_2 is Poly=False because of sorting, if not, check and swap\n",
    "        if not row_1['Is Poly']:\n",
    "            row_1, row_2 = row_2, row_1  # Swap if the first row is not Poly=True\n",
    "        \n",
    "        # Compare the metrics\n",
    "        better_metrics = sum(row_1[metric] <= row_2[metric] for metric in metrics)\n",
    "        if better_metrics >= 2:  # If at least two metrics are better or equal for Poly=True\n",
    "            best_combined.at[i, 'Poly_Performance'] = 1\n",
    "            best_combined.at[i + 1, 'Poly_Performance'] = 0\n",
    "        else:\n",
    "            # Mark these rows for removal\n",
    "            rows_to_remove.extend([i, i + 1])\n",
    "    else:\n",
    "        print('hi')\n",
    "        # Mark these rows for removal since they don't match the criteria\n",
    "        rows_to_remove.extend([i, i + 1])\n",
    "\n",
    "# Remove the rows that do not match the comparison criteria\n",
    "best_combined.drop(index=rows_to_remove, inplace=True)\n",
    "\n",
    "# Save the updated DataFrame back to Excel\n",
    "best_combined.to_excel('/home/../multiTS/NFT/models/tests/test_trend/best_rows_combined_updated.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the combined Excel file\n",
    "best_combined = pd.read_excel('/home/../multiTS/NFT/results/combined_data.xlsx')\n",
    "\n",
    "# Initialize the new columns with extracted substrings\n",
    "best_combined['series'] = best_combined['Data'].apply(lambda x: x[5:16])\n",
    "best_combined['year'] = best_combined['Data'].apply(lambda x: x[17:21])\n",
    "\n",
    "# Initialize the 'Poly_Performance' column with NaN (Not a Number)\n",
    "best_combined['Poly_Performance'] = pd.NA\n",
    "\n",
    "# Define the metrics you want to compare.\n",
    "metrics = ['test_mse', 'test_smape', 'test_mase']\n",
    "\n",
    "# Create a new DataFrame for the paired rows\n",
    "paired_rows = pd.DataFrame()\n",
    "\n",
    "# Function to find matching row\n",
    "def find_matching_row(current_row, all_rows):\n",
    "    for i, row in all_rows.iterrows():\n",
    "        # Check if the rows have the same values for specified columns and opposite values in 'Is Poly' column\n",
    "        if all(current_row[col] == row[col] for col in ['Data', 'Lookback', 'Horizon', 'Epochs', 'Blocks']) and current_row['Is Poly'] != row['Is Poly']:\n",
    "            return row\n",
    "    return None  # Return None if no match is found\n",
    "\n",
    "# Iterate over each row to find its pair based on specified conditions\n",
    "for index, row in best_combined.iterrows():\n",
    "    matched_row = find_matching_row(row, best_combined)\n",
    "    if matched_row is not None:\n",
    "        # Add the original row and its match to the new DataFrame\n",
    "        paired_row = pd.concat([row, matched_row]).to_frame().T\n",
    "        paired_rows = pd.concat([paired_rows, paired_row], ignore_index=True)\n",
    "\n",
    "# Resetting the index for paired_rows to ensure proper alignment\n",
    "paired_rows.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Determine Poly Performance for each pair and arrange them next to each other\n",
    "for i in range(0, len(paired_rows), 2):  # Process each pair\n",
    "    row_1 = paired_rows.iloc[i]\n",
    "    row_2 = paired_rows.iloc[i + 1]\n",
    "    # Assuming row_1 is Poly=True and row_2 is Poly=False because of sorting, if not, check and swap\n",
    "    if not row_1['Is Poly']:\n",
    "        row_1, row_2 = row_2, row_1  # Swap if the first row is not Poly=True\n",
    "\n",
    "    # Compare the metrics\n",
    "    better_metrics = sum(row_1[metric] <= row_2[metric] for metric in metrics)\n",
    "    if better_metrics >= 2:  # If at least two metrics are better or equal for Poly=True\n",
    "        paired_rows.at[i, 'Poly_Performance'] = 1\n",
    "        paired_rows.at[i + 1, 'Poly_Performance'] = 0\n",
    "\n",
    "# Save the paired DataFrame back to Excel\n",
    "paired_rows.to_excel('/home/../multiTS/NFT/models/tests/test_trend/paired_rows_combined.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the combined Excel file\n",
    "best_combined = pd.read_excel('/home/../multiTS/NFT/results/combined_data.xlsx')\n",
    "\n",
    "# Initialize the new columns with extracted substrings\n",
    "best_combined['series'] = best_combined['Data'].apply(lambda x: x[5:16])\n",
    "best_combined['year'] = best_combined['Data'].apply(lambda x: x[17:21])\n",
    "\n",
    "# Define the metrics you want to compare.\n",
    "metrics = ['test_mse', 'test_smape', 'test_mase']\n",
    "\n",
    "# Create a new DataFrame for the paired rows and their comparisons\n",
    "paired_rows = pd.DataFrame()\n",
    "\n",
    "# List to keep track of indices to drop from the original DataFrame\n",
    "indices_to_drop = []\n",
    "\n",
    "# Iterate over the DataFrame without modifying it while iterating\n",
    "for index, row in best_combined.iterrows():\n",
    "    # Skip if row already paired and marked for deletion\n",
    "    if index in indices_to_drop:\n",
    "        continue\n",
    "\n",
    "    # Finding the matching row\n",
    "    for match_index, match_row in best_combined.iterrows():\n",
    "        # Ensure not comparing the same row and hasn't been paired already\n",
    "        if index != match_index and match_index not in indices_to_drop:\n",
    "            # Check for same values in specified columns and opposite in 'Is Poly'\n",
    "            if all(row[col] == match_row[col] for col in ['Data', 'Lookback', 'Horizon', 'Epochs', 'Blocks']) and row['Is Poly'] != match_row['Is Poly']:\n",
    "                # Add index of matching row to list for removal\n",
    "                indices_to_drop.extend([index, match_index])\n",
    "\n",
    "                # Perform metrics comparison and assign Poly Performance\n",
    "                better_metrics = sum(row[metric] <= match_row[metric] for metric in metrics)\n",
    "                row['Poly_Performance'] = 1 if better_metrics >= 2 else 0\n",
    "                match_row['Poly_Performance'] = -1 if better_metrics < 2 else 0\n",
    "\n",
    "                # Combine the two rows and append to the new DataFrame\n",
    "                comparison_pair = pd.concat([row, match_row]).to_frame().T\n",
    "                paired_rows = pd.concat([paired_rows, comparison_pair], ignore_index=True)\n",
    "\n",
    "                # Break out of the inner loop once a match is found\n",
    "                break\n",
    "\n",
    "# Drop the paired rows from the original DataFrame\n",
    "best_combined = best_combined.drop(indices_to_drop).reset_index(drop=True)\n",
    "\n",
    "# Save the paired rows to a new Excel file\n",
    "paired_rows.to_excel('/home/../multiTS/NFT/models/tests/test_trend/paired_rows.xlsx', index=False)\n",
    "\n",
    "# Save the remaining unpaired rows back to a different Excel file\n",
    "best_combined.to_excel('/home/../multiTS/NFT/models/tests/test_trend/unpaired_rows.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multTS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
