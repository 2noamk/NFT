{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "sys.path.append('/home/noam.koren/multiTS/NFT/')\n",
    "from dicts import data_to_num_vars_dict\n",
    "\n",
    "sys.path.append('/home/noam.koren/multiTS/NFT/')\n",
    "from training_functions import read_all_data_and_print_stats, train_model, evaluate_model, save_model\n",
    "\n",
    "sys.path.append('/home/noam.koren/multiTS/NFT/models/baseline_models/')\n",
    "from base_models import FC, MV_LSTM, CNN, TCN, TimeSeriesTransformer\n",
    "\n",
    "data = 'air_quality'\n",
    "\n",
    "NUM_OF_VARS = data_to_num_vars_dict[data]\n",
    "LOOKBACK = 5\n",
    "HORIZON = 1\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 5\n",
    "PLOT_EPOCH = NUM_EPOCHS\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "save_model_path = f\"/home/noam.koren/multiTS/NFT/models/baseline_models/{data}/\"\n",
    "\n",
    "n_people = 600\n",
    "n_rows = 700\n",
    "    \n",
    "class dataset(Dataset):\n",
    "    def __init__(self, data, target):\n",
    "        self.input = data\n",
    "        self.target = target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input)\n",
    "\n",
    "    def __getitem__(self, idx): \n",
    "        return self.input[idx], self.target[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data == 'ecg':\n",
    "    data_path = f\"/home/noam.koren/multiTS/NFT/data/{data}/{data}_{LOOKBACK}l_{HORIZON}h_{n_people}people_{n_rows}rows/\"\n",
    "else:\n",
    "    data_path = f\"/home/noam.koren/multiTS/NFT/data/{data}/{data}_{LOOKBACK}l_{HORIZON}h/\"\n",
    "\n",
    "train_X, train_y, val_X, val_y, test_X, test_y = read_all_data_and_print_stats(data_path=data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_model = FC(input_dim=NUM_OF_VARS, \n",
    "              output_dim=NUM_OF_VARS,\n",
    "              horizon=HORIZON, \n",
    "              device=device).to(device)\n",
    "\n",
    "train_model(dataset=dataset, \n",
    "            epochs=NUM_EPOCHS, \n",
    "            model=fc_model, \n",
    "            train_X=train_X.to(device), train_y=train_y.to(device),\n",
    "            val_X=val_X.to(device), val_y=val_y.to(device), \n",
    "            device=device, \n",
    "            lookback=LOOKBACK,\n",
    "            horizon=HORIZON, \n",
    "            n_vars=NUM_OF_VARS, \n",
    "            batch_size=BATCH_SIZE, \n",
    "            print_epoch=PLOT_EPOCH, \n",
    "            path_to_save_prediction_plots=None)\n",
    "\n",
    "evaluate_model(fc_model, train_X, train_y, val_X, val_y, test_X, test_y)\n",
    "\n",
    "save_model(fc_model, \"fc\", data, save_model_path, LOOKBACK, HORIZON, n_people, n_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = MV_LSTM(num_vars=NUM_OF_VARS, \n",
    "                     lookback=LOOKBACK, \n",
    "                     horizon=HORIZON, \n",
    "                     hidden_dim=50, \n",
    "                     num_layers=2, \n",
    "                     device=device).to(device)\n",
    "\n",
    "train_model(dataset=dataset, \n",
    "            epochs=NUM_EPOCHS, \n",
    "            model=lstm_model, \n",
    "            train_X=train_X.to(device), train_y=train_y.to(device),\n",
    "            val_X=val_X.to(device), val_y=val_y.to(device), \n",
    "            device=device, \n",
    "            lookback=LOOKBACK,\n",
    "            horizon=HORIZON, \n",
    "            n_vars=NUM_OF_VARS, \n",
    "            batch_size=BATCH_SIZE, \n",
    "            print_epoch=PLOT_EPOCH, \n",
    "            path_to_save_prediction_plots=None)\n",
    "\n",
    "evaluate_model(lstm_model, train_X, train_y, val_X, val_y, test_X, test_y)\n",
    "\n",
    "save_model(lstm_model, \"lstm\", data, save_model_path, LOOKBACK, HORIZON, n_people, n_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = CNN(lookback=LOOKBACK, \n",
    "                horizon=HORIZON, \n",
    "                num_vars=NUM_OF_VARS,\n",
    "                device=device,\n",
    "                num_channels=[16], \n",
    "                kernel_size=2, \n",
    "                dropout=0.2).to(device)\n",
    "\n",
    "train_model(dataset=dataset,\n",
    "            epochs=NUM_EPOCHS,\n",
    "            model=cnn_model, \n",
    "            train_X=train_X.to(device), train_y=train_y.to(device),\n",
    "            val_X=val_X.to(device), val_y=val_y.to(device), \n",
    "            device=device, \n",
    "            lookback=LOOKBACK,\n",
    "            horizon=HORIZON, \n",
    "            n_vars=NUM_OF_VARS, \n",
    "            batch_size=BATCH_SIZE, \n",
    "            print_epoch=PLOT_EPOCH, \n",
    "            path_to_save_prediction_plots=None\n",
    "            )\n",
    "\n",
    "evaluate_model(cnn_model, train_X, train_y, val_X, val_y, test_X, test_y)\n",
    "\n",
    "save_model(cnn_model, \"cnn\", data, save_model_path, LOOKBACK, HORIZON, n_people, n_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcn_model = TCN(lookback=LOOKBACK, \n",
    "                horizon=HORIZON, \n",
    "                num_vars=NUM_OF_VARS, \n",
    "                device=device,\n",
    "                num_channels=[25, 50], \n",
    "                kernel_size=2, \n",
    "                dropout=0.2).to(device)\n",
    "\n",
    "train_model(dataset=dataset,\n",
    "            epochs=NUM_EPOCHS,\n",
    "            model=tcn_model, \n",
    "            train_X=train_X.to(device), train_y=train_y.to(device),\n",
    "            val_X=val_X.to(device), val_y=val_y.to(device), \n",
    "            device=device, \n",
    "            lookback=LOOKBACK,\n",
    "            horizon=HORIZON, \n",
    "            n_vars=NUM_OF_VARS, \n",
    "            batch_size=BATCH_SIZE, \n",
    "            print_epoch=PLOT_EPOCH, \n",
    "            path_to_save_prediction_plots=None\n",
    "            )\n",
    "\n",
    "evaluate_model(tcn_model, train_X, train_y, val_X, val_y, test_X, test_y)\n",
    "\n",
    "save_model(tcn_model, \"tcn\", data, save_model_path, LOOKBACK, HORIZON, n_people, n_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model = TimeSeriesTransformer(\n",
    "    lookback=LOOKBACK,\n",
    "    horizon=HORIZON,\n",
    "    num_vars=NUM_OF_VARS,\n",
    "    device=device,\n",
    "    num_layers=1,\n",
    "    num_heads=1,\n",
    "    dim_feedforward=16,\n",
    ").to(device)\n",
    "\n",
    "train_model(dataset=dataset, \n",
    "            epochs=NUM_EPOCHS, \n",
    "            model=transformer_model, \n",
    "            train_X=train_X.to(device), train_y=train_y.to(device),\n",
    "            val_X=val_X.to(device), val_y=val_y.to(device), \n",
    "            device=device, \n",
    "            lookback=LOOKBACK,\n",
    "            horizon=HORIZON, \n",
    "            n_vars=NUM_OF_VARS, \n",
    "            batch_size=BATCH_SIZE, \n",
    "            print_epoch=PLOT_EPOCH, \n",
    "            path_to_save_prediction_plots=None)\n",
    "\n",
    "evaluate_model(transformer_model, train_X, train_y, val_X, val_y, test_X, test_y)\n",
    "\n",
    "save_model(transformer_model, \"transformer\", data, save_model_path, LOOKBACK, HORIZON, n_people, n_rows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multTS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
