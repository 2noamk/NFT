{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from torch.utils.data import Dataset\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import os\n",
    "\n",
    "class dataset(Dataset):\n",
    "    def __init__(self, X, y, lookback, horizon, label_len=0, data_stamp=None):\n",
    "        self.seq_len = lookback\n",
    "        self.pred_len = horizon\n",
    "        self.label_len = label_len\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "        self.add_date = True if data_stamp is not None else False\n",
    "        if self.add_date:\n",
    "            self.X_mark = []\n",
    "            self.y_mark = []\n",
    "            \n",
    "        for index in range(0, len(X) - (self.seq_len + self.pred_len)):  \n",
    "            s_begin = index\n",
    "            s_end = s_begin + self.seq_len\n",
    "            r_begin = s_end - self.label_len\n",
    "            r_end = r_begin + self.label_len + self.pred_len\n",
    "\n",
    "            seq_x =X[s_begin:s_end]\n",
    "            seq_y = y[r_begin:r_end]\n",
    "            seq_x_mark = data_stamp[s_begin:s_end]\n",
    "            seq_y_mark = data_stamp[r_begin:r_end]\n",
    "            \n",
    "            self.X.append(seq_x)\n",
    "            self.y.append(seq_y)\n",
    "            if self.add_date:\n",
    "                self.X_mark.append(seq_x_mark)\n",
    "                self.y_mark.append(seq_y_mark)\n",
    "\n",
    "        self.X = torch.stack(self.X)\n",
    "        self.y = torch.stack(self.y)\n",
    "        if self.add_date:\n",
    "            self.X_mark = np.stack(self.X_mark)\n",
    "            self.y_mark = np.stack(self.y_mark)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.add_date: return self.X[idx], self.y[idx], self.X_mark[idx], self.y_mark[idx]\n",
    "        return self.X[idx], self.y[idx]\n",
    "   \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'traffic'\n",
    "base_path = f'/home/noam.koren/multiTS/NFT/data/{data}/' \n",
    "lookback=96\n",
    "label_len=0\n",
    "\n",
    "for horizon in [1, 16, 32, 48]:\n",
    "    for flag in ['train', 'val', 'test']:\n",
    "        X = torch.tensor(pd.read_pickle(f'{base_path}{flag}_X.pkl'))\n",
    "        y = torch.tensor(pd.read_pickle(f'{base_path}{flag}_y.pkl'))\n",
    "        data_stamp = torch.tensor(pd.read_pickle(f'{base_path}{flag}_data_stamp.pkl'))\n",
    "        \n",
    "        d = dataset(\n",
    "            X=X, \n",
    "            y=y, \n",
    "            lookback=lookback, \n",
    "            horizon=horizon, \n",
    "            label_len=label_len, \n",
    "            data_stamp=data_stamp\n",
    "        )\n",
    "        \n",
    "        path = f'{base_path}{data}_{lookback}l_{horizon}h_{label_len}label/'\n",
    "        mark_path = f'{base_path}{data}_date_stamp_{lookback}l_{horizon}h_{label_len}label/'\n",
    "\n",
    "        # Check if directories exist, create if not\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        if not os.path.exists(mark_path):\n",
    "            os.makedirs(mark_path)\n",
    "\n",
    "\n",
    "        # Convert tensor to a NumPy array if it's on GPU, you might need to call .cpu() before .numpy()\n",
    "        X_np = d.X.cpu().numpy() if d.X.is_cuda else d.X.numpy()\n",
    "        y_np = d.y.cpu().numpy() if d.y.is_cuda else d.y.numpy()\n",
    "\n",
    "        # Save using pandas.to_pickle\n",
    "        pd.to_pickle(X_np, f'{path}/{flag}_X.pkl')\n",
    "        pd.to_pickle(y_np, f'{path}/{flag}_y.pkl')\n",
    "\n",
    "        # For the date_stamp tensor, do the same if it's a tensor\n",
    "        if isinstance(d.X_mark, torch.Tensor):\n",
    "            X_mark_np = d.X_mark.cpu().numpy() if d.X_mark.is_cuda else d.X_mark.numpy()\n",
    "            pd.to_pickle(X_mark_np, f'{mark_path}/{flag}_X.pkl')\n",
    "            y_mark_np = d.y_mark.cpu().numpy() if d.y_mark.is_cuda else d.y_mark.numpy()\n",
    "            pd.to_pickle(y_mark_np, f'{mark_path}/{flag}_y.pkl')\n",
    "        else:\n",
    "            pd.to_pickle(d.X_mark, f'{mark_path}/{flag}_X.pkl')\n",
    "            pd.to_pickle(d.y_mark, f'{mark_path}/{flag}_y.pkl')\n",
    "\n",
    "\n",
    "        # pd.to_pickle(f'{base_path}electricity_{lookback}l_{horizon}h_{label_len}label/{flag}_X.pkl', d.X)\n",
    "        # pd.to_pickle(f'{base_path}electricity_{lookback}l_{horizon}h_{label_len}label/{flag}_y.pkl', d.y)\n",
    "        # pd.to_pickle(f'{base_path}electricity_date_Stamp_{lookback}l_{horizon}h_{label_len}label/{flag}_X.pkl', d.X_mark)\n",
    "        # pd.to_pickle(f'{base_path}electricity_date_Stamp_{lookback}l_{horizon}h_{label_len}label/{flag}_y.pkl', d.y_mark)\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 1 X: (18315, 96, 321)\n",
      "train 1 y: (18315, 1, 321)\n",
      "val 1 X: (2631, 96, 321)\n",
      "val 1 y: (2631, 1, 321)\n",
      "test 1 X: (5259, 96, 321)\n",
      "test 1 y: (5259, 1, 321)\n",
      "train 16 X: (18300, 96, 321)\n",
      "train 16 y: (18300, 16, 321)\n",
      "val 16 X: (2616, 96, 321)\n",
      "val 16 y: (2616, 16, 321)\n",
      "test 16 X: (5244, 96, 321)\n",
      "test 16 y: (5244, 16, 321)\n",
      "train 32 X: (18284, 96, 321)\n",
      "train 32 y: (18284, 32, 321)\n",
      "val 32 X: (2600, 96, 321)\n",
      "val 32 y: (2600, 32, 321)\n",
      "test 32 X: (5228, 96, 321)\n",
      "test 32 y: (5228, 32, 321)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "base_path = f'/home/noam.koren/multiTS/NFT/data/{data}/{data}_96l_' \n",
    "lookback=96\n",
    "label_len=0\n",
    "\n",
    "for horizon in [1, 16, 32]:\n",
    "    for flag in ['train', 'val', 'test']:\n",
    "        X = pd.read_pickle(f'{base_path}{horizon}h_0label/{flag}_X.pkl')\n",
    "        y = pd.read_pickle(f'{base_path}{horizon}h_0label/{flag}_y.pkl')\n",
    "        print(f\"{flag} {horizon} X: {X.shape}\")\n",
    "        print(f\"{flag} {horizon} y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multTS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
