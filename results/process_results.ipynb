{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File has been created successfully!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"average noaa\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "data = 'noaa'\n",
    "for model in ['TimeMixer']:\n",
    "    base_path = f'/home/../multiTS/NFT/results/{data}/{model}/{model}'\n",
    "    # Load the three Excel files\n",
    "    file1 = f'{base_path}_{data}_AE000041196_None_results.xlsx'\n",
    "    file2 = f'{base_path}_{data}_AEM00041194_None_results.xlsx'\n",
    "    file3 = f'{base_path}_{data}_AEM00041217_None_results.xlsx'\n",
    "\n",
    "    df1 = pd.read_excel(file1)\n",
    "    df2 = pd.read_excel(file2)\n",
    "    df3 = pd.read_excel(file3)\n",
    "\n",
    "    # Ensure the Data column is standardized before merging\n",
    "    df1['Data'] = data\n",
    "    df2['Data'] = data\n",
    "    df3['Data'] = data\n",
    "\n",
    "    # Combine the three dataframes\n",
    "    combined_df = pd.concat([df1, df2, df3])\n",
    "\n",
    "    # Group by 'Data', 'Lookback', and 'Horizon' and calculate mean of the selected columns\n",
    "    result_df = combined_df.groupby(['Data', 'Lookback', 'Horizon']).agg({\n",
    "    'test_mse': 'mean',\n",
    "    'test_mae': 'mean',\n",
    "    'test_smape': 'mean',\n",
    "    'test_mase': 'mean'\n",
    "    }).reset_index()\n",
    "\n",
    "    # Write the resulting DataFrame to a new Excel file\n",
    "    result_df.to_excel(f'{base_path}_averaged.xlsx', index=False)\n",
    "\n",
    "    print(\"File has been created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/../multiTS/NFT/results/ecg_single/UMixer/UMixer_ecg_single_E00001_results.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m file3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_E00003_results.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     11\u001b[0m file4 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_E00004_results.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 13\u001b[0m df1 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m df2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(file2)\n\u001b[1;32m     15\u001b[0m df3 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(file3)\n",
      "File \u001b[0;32m~/miniconda3/envs/nft/lib/python3.9/site-packages/pandas/io/excel/_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/nft/lib/python3.9/site-packages/pandas/io/excel/_base.py:1550\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1550\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m   1552\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1557\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/nft/lib/python3.9/site-packages/pandas/io/excel/_base.py:1402\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m   1400\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[0;32m-> 1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m   1404\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[1;32m   1405\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[1;32m   1406\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/nft/lib/python3.9/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/../multiTS/NFT/results/ecg_single/UMixer/UMixer_ecg_single_E00001_results.xlsx'"
     ]
    }
   ],
   "source": [
    "\"\"\"average ecg\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "data = 'ecg_single'\n",
    "for model in ['CycleNet']:#'PatchTST', 'lstm', 'tcn', 'TimesNet']:\n",
    "    base_path = f'/home/../multiTS/NFT/results/{data}/{model}/{model}'\n",
    "    # Load the three Excel files\n",
    "    file1 = f'{base_path}_{data}_E00001_results.xlsx'\n",
    "    file2 = f'{base_path}_{data}_E00002_results.xlsx'\n",
    "    file3 = f'{base_path}_{data}_E00003_results.xlsx'\n",
    "    file4 = f'{base_path}_{data}_E00004_results.xlsx'\n",
    "\n",
    "    df1 = pd.read_excel(file1)\n",
    "    df2 = pd.read_excel(file2)\n",
    "    df3 = pd.read_excel(file3)\n",
    "    df4 = pd.read_excel(file4)\n",
    "\n",
    "    # Ensure the Data column is standardized before merging\n",
    "    df1['Data'] = data\n",
    "    df2['Data'] = data\n",
    "    df3['Data'] = data\n",
    "    df4['Data'] = data\n",
    "\n",
    "    # Combine the three dataframes\n",
    "    combined_df = pd.concat([df1, df2, df3, df4])\n",
    "\n",
    "    # Group by 'Data', 'Lookback', and 'Horizon' and calculate mean of the selected columns\n",
    "    result_df = combined_df.groupby(['Data', 'Lookback', 'Horizon']).agg({\n",
    "    'test_mse': 'mean',\n",
    "    'test_mae': 'mean',\n",
    "    'test_smape': 'mean',\n",
    "    'test_mase': 'mean'\n",
    "    }).reset_index()\n",
    "\n",
    "    # Write the resulting DataFrame to a new Excel file\n",
    "    result_df.to_excel(f'{base_path}_averaged.xlsx', index=False)\n",
    "\n",
    "    print(\"File has been created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 files for model TSLANet\n",
      "Averaged results saved to /home/../multiTS/NFT/results/ecg_single/TSLANet/TSLANet_averaged.xlsx\n",
      "Found 4 files for model iTransformer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged results saved to /home/../multiTS/NFT/results/ecg_single/iTransformer/iTransformer_averaged.xlsx\n",
      "Found 4 files for model FiLM\n",
      "Averaged results saved to /home/../multiTS/NFT/results/ecg_single/FiLM/FiLM_averaged.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "data = 'ecg_single'\n",
    "for model in ['TSLANet', 'iTransformer', 'FiLM']:  # 'nft', 'ATFNet', 'PatchTST', 'lstm', 'tcn', 'TimesNet' \n",
    "    base_path = f'/home/../multiTS/NFT/results/{data}/{model}/{model}'\n",
    "    \n",
    "    # Find all Excel files matching the pattern\n",
    "    files = glob.glob(f'{base_path}_{data}_E*_results.xlsx')\n",
    "    print(f\"Found {len(files)} files for model {model}\")\n",
    "\n",
    "    # Load all files into a list of DataFrames\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        df = pd.read_excel(file)\n",
    "        df['Data'] = data  # Ensure the 'Data' column is standardized\n",
    "        dfs.append(df)\n",
    "\n",
    "    # Combine all DataFrames\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Group by 'Data', 'Lookback', and 'Horizon' and calculate mean\n",
    "    result_df = combined_df.groupby(['Data', 'Lookback', 'Horizon']).agg({\n",
    "        'test_mse': 'mean',\n",
    "        'test_mae': 'mean',\n",
    "        'test_smape': 'mean',\n",
    "        'test_mase': 'mean'\n",
    "    }).reset_index()\n",
    "\n",
    "    # Save the averaged results\n",
    "    output_file = f'{base_path}_averaged.xlsx'\n",
    "    result_df.to_excel(output_file, index=False)\n",
    "\n",
    "    print(f\"Averaged results saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 files for model CycleNet\n",
      "Averaged results saved to /home/../multiTS/NFT/results/eeg_single/CycleNet/CycleNet_averaged.xlsx\n"
     ]
    }
   ],
   "source": [
    "data = 'eeg_single'\n",
    "for model in ['CycleNet', ]:  # You can add more models here\n",
    "    base_path = f'/home/../multiTS/NFT/results/{data}/{model}/{model}'\n",
    "    \n",
    "    # Find all Excel files matching the pattern\n",
    "    files = glob.glob(f'{base_path}_{data}_*.xlsx')\n",
    "    print(f\"Found {len(files)} files for model {model}\")\n",
    "\n",
    "    # Load all files into a list of DataFrames\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        df = pd.read_excel(file)\n",
    "        df['Data'] = data  # Ensure the 'Data' column is standardized\n",
    "        dfs.append(df)\n",
    "\n",
    "    # Combine all DataFrames\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Group by 'Data', 'Lookback', and 'Horizon' and calculate mean\n",
    "    result_df = combined_df.groupby(['Data', 'Lookback', 'Horizon']).agg({\n",
    "        'test_mse': 'mean',\n",
    "        'test_mae': 'mean',\n",
    "        'test_smape': 'mean',\n",
    "        'test_mase': 'mean'\n",
    "    }).reset_index()\n",
    "\n",
    "    # Save the averaged results\n",
    "    output_file = f'{base_path}_averaged.xlsx'\n",
    "    result_df.to_excel(output_file, index=False)\n",
    "\n",
    "    print(f\"Averaged results saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File has been created successfully!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"average eeg\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "data = 'eeg_single'\n",
    "for model in ['nbeats']:\n",
    "    base_path = f'/home/../multiTS/NFT/results/{data}/{model}/{model}'\n",
    "    # Load the three Excel files\n",
    "    file1 = f'{base_path}_{data}_test_0_results.xlsx'\n",
    "    file2 = f'{base_path}_{data}_test_1_results.xlsx'\n",
    "\n",
    "    df1 = pd.read_excel(file1)\n",
    "    df2 = pd.read_excel(file2)\n",
    "\n",
    "    # Ensure the Data column is standardized before merging\n",
    "    df1['Data'] = data\n",
    "    df2['Data'] = data\n",
    "\n",
    "    # Combine the three dataframes\n",
    "    combined_df = pd.concat([df1, df2])\n",
    "\n",
    "    # Group by 'Data', 'Lookback', and 'Horizon' and calculate mean of the selected columns\n",
    "    result_df = combined_df.groupby(['Data', 'Lookback', 'Horizon']).agg({\n",
    "    'test_mse': 'mean',\n",
    "    'test_mae': 'mean',\n",
    "    'test_smape': 'mean',\n",
    "    'test_mase': 'mean'\n",
    "    }).reset_index()\n",
    "\n",
    "    # Write the resulting DataFrame to a new Excel file\n",
    "    result_df.to_excel(f'{base_path}_averaged.xlsx', index=False)\n",
    "\n",
    "    print(\"File has been created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Base directory containing the results\n",
    "base_dir = \"/home/../multiTS/NFT/results\"\n",
    "\n",
    "# Create an output directory for the merged Excel files\n",
    "output_dir = os.path.join(base_dir, \"merged_results\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Filter directories with the specific format\n",
    "dirs = [\n",
    "    d for d in os.listdir(base_dir)\n",
    "    if os.path.isdir(os.path.join(base_dir, d)) and re.match(r'seasonal_\\d+_trend_\\d+', d)\n",
    "]\n",
    "\n",
    "\n",
    "# Process each directory\n",
    "for dir_name in dirs:\n",
    "    dir_path = os.path.join(base_dir, dir_name)\n",
    "    models = [\"DLinear\", \"nft\", \"PatchTST\", \"Timesnet\"]\n",
    "    merged_data = None\n",
    "\n",
    "    # Process each model's Excel file in the directory\n",
    "    for model in models:\n",
    "        model_path = os.path.join(dir_path, model)\n",
    "        excel_file = os.path.join(model_path, f\"{model}_{dir_name}_results.xlsx\")\n",
    "        if os.path.exists(excel_file):\n",
    "            # Read the Excel file\n",
    "            df = pd.read_excel(excel_file)\n",
    "            # Select relevant columns\n",
    "            subset_df = df[[\"Data\", \"Lookback\", \"Horizon\", \"test_mse\"]].rename(columns={\"test_mse\": model})\n",
    "            # Merge data\n",
    "            if merged_data is None:\n",
    "                merged_data = subset_df\n",
    "            else:\n",
    "                merged_data = pd.merge(merged_data, subset_df, on=[\"Data\", \"Lookback\", \"Horizon\"], how=\"outer\")\n",
    "\n",
    "    # Save the merged data to a new Excel file\n",
    "    if merged_data is not None:\n",
    "        output_file = os.path.join(output_dir, f\"{dir_name}.xlsx\")\n",
    "        merged_data.to_excel(output_file, index=False)\n",
    "\n",
    "output_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 files for model TimeMixer\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m     dfs\u001b[38;5;241m.\u001b[39mappend(df)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Combine all DataFrames\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m combined_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Group by 'Data', 'Lookback', and 'Horizon' and calculate mean\u001b[39;00m\n\u001b[1;32m     24\u001b[0m result_df \u001b[38;5;241m=\u001b[39m combined_df\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLookback\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHorizon\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39magg({\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_mse\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_mae\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_smape\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_mase\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     29\u001b[0m })\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "File \u001b[0;32m~/miniconda3/envs/new_env/lib/python3.9/site-packages/pandas/core/reshape/concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 382\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/miniconda3/envs/new_env/lib/python3.9/site-packages/pandas/core/reshape/concat.py:445\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[0;32m--> 445\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[1;32m    448\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[0;32m~/miniconda3/envs/new_env/lib/python3.9/site-packages/pandas/core/reshape/concat.py:507\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[0;34m(self, objs, keys)\u001b[0m\n\u001b[1;32m    504\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs_list))\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "data = 'ecg_single'\n",
    "for model in ['TimeMixer']:  # You can add more models here\n",
    "    base_path = f'/home/../multiTS/NFT/results/{data}/{model}/{model}'\n",
    "    \n",
    "    # Find all Excel files matching the pattern\n",
    "    files = glob.glob(f'{base_path}_{data}_E*_None_*_results.xlsx')\n",
    "    print(f\"Found {len(files)} files for model {model}\")\n",
    "\n",
    "    # Load all files into a list of DataFrames\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        df = pd.read_excel(file)\n",
    "        df['Data'] = data  # Ensure the 'Data' column is standardized\n",
    "        dfs.append(df)\n",
    "\n",
    "    # Combine all DataFrames\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Group by 'Data', 'Lookback', and 'Horizon' and calculate mean\n",
    "    result_df = combined_df.groupby(['Data', 'Lookback', 'Horizon']).agg({\n",
    "        'test_mse': 'mean',\n",
    "        'test_mae': 'mean',\n",
    "        'test_smape': 'mean',\n",
    "        'test_mase': 'mean'\n",
    "    }).reset_index()\n",
    "\n",
    "    # Save the averaged results\n",
    "    output_file = f'{base_path}_averaged.xlsx'\n",
    "    result_df.to_excel(output_file, index=False)\n",
    "\n",
    "    print(f\"Averaged results saved to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
